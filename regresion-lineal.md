## üìå **Concepto de Regresi√≥n**:

-   La regresi√≥n es un m√©todo para **ajustar curvas a los datos**.
-   Se utiliza para predecir un **valor num√©rico** en lugar de una clase (como en clasificaci√≥n).
-   La forma general de una regresi√≥n lineal es:

    $$
    f(x) = wx + b
    $$

    Donde:

    -   $w$ es el coeficiente o pendiente de la l√≠nea.
    -   $b$ es el sesgo o intercepto en el eje $y$.

---

## üè° **Ejemplos Comunes**:

1. **Precio de una casa**:

    - Predecir el valor de una casa con base en caracter√≠sticas como el tama√±o, ubicaci√≥n, n√∫mero de habitaciones, etc.

2. **Cantidad de seguidores en redes sociales**:

    - Predecir el n√∫mero de seguidores seg√∫n la actividad y el alcance de las publicaciones.

3. **Predicci√≥n de ventas**:

    - Estimar las ventas futuras de un producto seg√∫n datos hist√≥ricos.

---

## ‚öôÔ∏è **Funci√≥n de P√©rdida (Loss Function) vs M√©trica (Metric)**:

-   La **funci√≥n de p√©rdida (Loss Function)** es lo que el modelo intenta minimizar durante el entrenamiento.

    -   Ejemplos: **Mean Squared Error (MSE)**, **Mean Absolute Error (MAE)**.

-   Las **m√©tricas (Metrics)** son utilizadas por las personas para evaluar el rendimiento del modelo, pero **no influyen en el entrenamiento**.

    -   Ejemplo: **R¬≤ (Coeficiente de determinaci√≥n)** para medir qu√© tan bien se ajusta el modelo.

---

## üîé **M√©tricas Comunes para Regresi√≥n**:

1. **Mean Squared Error (MSE)**:

    $$
    MSE = \frac{1}{n} \sum_{i=1}^n (y_i - \hat{y_i})^2
    $$

    - Penaliza m√°s los errores grandes, ya que est√°n elevados al cuadrado.

2. **Mean Absolute Error (MAE)**:

    $$
    MAE = \frac{1}{n} \sum_{i=1}^n |y_i - \hat{y_i}|
    $$

    - Penaliza de forma lineal, es m√°s robusto a outliers.

---

## üìà **Regresi√≥n Lineal Simple**:

-   Se ajusta una l√≠nea recta para modelar la relaci√≥n entre una **variable independiente (x)** y una **dependiente (y)**.
-   El objetivo es encontrar los mejores valores para $w$ (pendiente) y $b$ (intercepto) que minimicen el error.

**Ejemplo**:

-   Queremos predecir el precio de un auto en funci√≥n de su antig√ºedad.

    -   Si un auto tiene 5 a√±os, el modelo podr√≠a predecir un valor aproximado de acuerdo a la l√≠nea ajustada.

---

## üó∫Ô∏è **Regresi√≥n Lineal Multidimensional**:

-   Se extiende el concepto para m√∫ltiples variables independientes.
-   La f√≥rmula general es:

    $$
    f(x) = w_0 + w_1x_1 + w_2x_2 + ... + w_nx_n
    $$

    -   $w_0$ es el sesgo.
    -   Los dem√°s $w_i$ son los pesos correspondientes a cada caracter√≠stica.
    -   Cada **x** representa una caracter√≠stica del dataset.

**Ejemplo**:

-   Predicci√≥n del precio de una casa en funci√≥n de:

    -   Tama√±o (m¬≤),
    -   N√∫mero de habitaciones,
    -   Localizaci√≥n,
    -   Antig√ºedad, etc.

---

## üßÆ **Optimizaci√≥n del Modelo: Descenso de Gradiente (Gradient Descent)**:

-   Es el m√©todo usado para minimizar la funci√≥n de p√©rdida.
-   **Paso a paso**:

    1. Se calculan las predicciones del modelo.
    2. Se mide el error (MSE o MAE).
    3. Se ajustan los pesos $w$ y el sesgo $b$ para reducir ese error.
    4. Se repite hasta encontrar el m√≠nimo.

**Tipos de Descenso de Gradiente**:

1. **Batch Gradient Descent**:

    - Se actualizan los pesos utilizando todo el conjunto de datos en cada iteraci√≥n.

2. **Stochastic Gradient Descent (SGD)**:

    - Los pesos se actualizan para cada muestra, lo que lo hace m√°s r√°pido pero ruidoso.

---

## üìù **Resumen General**:

| **Concepto**                             | **Descripci√≥n**                                                      | **Ejemplo**                                                          |
| ---------------------------------------- | -------------------------------------------------------------------- | -------------------------------------------------------------------- |
| **Regresi√≥n Lineal Simple**              | Relaci√≥n entre una sola variable independiente y una dependiente.    | Predecir el precio de un auto seg√∫n su antig√ºedad.                   |
| **Regresi√≥n Lineal M√∫ltiple**            | Relaci√≥n entre m√∫ltiples variables independientes y una dependiente. | Estimar el precio de una casa en funci√≥n del tama√±o, ubicaci√≥n, etc. |
| **Funci√≥n de P√©rdida (MSE, MAE)**        | M√©trica que el modelo minimiza para mejorar la predicci√≥n.           | MSE penaliza m√°s los errores grandes.                                |
| **Optimizaci√≥n (Descenso de Gradiente)** | M√©todo iterativo para ajustar los pesos del modelo.                  | SGD ajusta los pesos en cada muestra.                                |

---
